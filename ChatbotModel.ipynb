{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChatbotModel",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f0cc19dbaaca4c50979e1fb841dabc3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_591f378101fc446f85fb36ded6b29968",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_85579c3ad49a4c389f752e28650cd2b2",
              "IPY_MODEL_f9fdda14f7744c8d8b946df57cefd798"
            ]
          }
        },
        "591f378101fc446f85fb36ded6b29968": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85579c3ad49a4c389f752e28650cd2b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_204da43c2f904e4dbd20d954e374bf2e",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 200,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 200,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0f2451d81ca84363916d00836088e227"
          }
        },
        "f9fdda14f7744c8d8b946df57cefd798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3997a82b4bbe4e72b498932a13371734",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 200/200 [00:03&lt;00:00, 63.52it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_150626e5babf4b139e0f408ca8455392"
          }
        },
        "204da43c2f904e4dbd20d954e374bf2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0f2451d81ca84363916d00836088e227": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3997a82b4bbe4e72b498932a13371734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "150626e5babf4b139e0f408ca8455392": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sboomi/chatbot-api/blob/main/ChatbotModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fYmhokZKXj0"
      },
      "source": [
        "# Build a chatbot (Torch)\r\n",
        "\r\n",
        "A chatbot is very useful for companies because it can interact with a customer and provide useful information on the service without getting past the main page in some of the cases.\r\n",
        "\r\n",
        "A chatbot works by parsing the contents from a message the user sent, analyze it and return the appropriate response. \r\n",
        "\r\n",
        "A chatbot can be coded with DL using a **recurrent neural network (RNN)**. It needs an `intents.json` file for the bot to work.\r\n",
        "\r\n",
        "An `intents.json` file is written like this\r\n",
        "\r\n",
        "```json\r\n",
        "{\"intents\": [\r\n",
        "        {\"tag\": \"greeting\",\r\n",
        "         \"patterns\": [\"Hi there\", \"How are you\", \"Is anyone there?\", \"Hello\", \"Good day\"],\r\n",
        "         \"responses\": [\"Hello, thanks for asking\", \"Good to see you again\", \"Hi there, how can I help?\"],\r\n",
        "         \"context\": [\"\"]\r\n",
        "        },\r\n",
        "        {\"tag\": \"goodbye\",\r\n",
        "         \"patterns\": [\"Bye\", \"See you later\", \"Goodbye\", \"Nice chatting to you, bye\", \"Till next time\"],\r\n",
        "         \"responses\": [\"See you!\", \"Have a nice day\", \"Bye! Come back again soon.\"],\r\n",
        "         \"context\": [\"\"]\r\n",
        "        },\r\n",
        "        //...\r\n",
        "        ]\r\n",
        "}\r\n",
        "```\r\n",
        "\r\n",
        "It takes a list of objects tagged by topic, conaining a list of patterns to detect and responses to answer with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uJ9PCWkI1bA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3331d483-34ed-4c2e-9ed5-997fe873ff39"
      },
      "source": [
        "import torch\r\n",
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('wordnet')\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "import json\r\n",
        "import pickle\r\n",
        "from pathlib import Path\r\n",
        "import random\r\n",
        "import numpy as np\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch.utils.data import TensorDataset, DataLoader\r\n",
        "from tqdm.notebook import tqdm, trange\r\n",
        "import matplotlib.pyplot as plt\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNkTFz2cHXYF"
      },
      "source": [
        "First let's import the `intents.json` file and open it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKO_Nt2jKXJX",
        "outputId": "9665dd37-4ce4-41e4-ddbc-552d2ae4cfa0"
      },
      "source": [
        "path_data = Path('drive/MyDrive/data/chatbot/intents.json')\r\n",
        "path_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('drive/MyDrive/data/chatbot/intents.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud0GprOrKUrQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c8857ab-5e99-4954-86d7-052baaf3cbd0"
      },
      "source": [
        "with open(path_data, 'r') as f:\r\n",
        "  intents = json.load(f)\r\n",
        "\r\n",
        "for intent in intents['intents']:\r\n",
        "  print(\"Category:\", intent['tag'])\r\n",
        "  print(\"Data:\\n\", intent['patterns'])\r\n",
        "  print(\"Possible responses:\\n\", intent['responses'])\r\n",
        "  print(\"Context:\\n\", intent['context'], '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Category: greeting\n",
            "Data:\n",
            " ['Hi there', 'How are you', 'Is anyone there?', 'Hey', 'Hola', 'Hello', 'Good day']\n",
            "Possible responses:\n",
            " ['Hello, thanks for asking', 'Good to see you again', 'Hi there, how can I help?']\n",
            "Context:\n",
            " [''] \n",
            "\n",
            "Category: goodbye\n",
            "Data:\n",
            " ['Bye', 'See you later', 'Goodbye', 'Nice chatting to you, bye', 'Till next time']\n",
            "Possible responses:\n",
            " ['See you!', 'Have a nice day', 'Bye! Come back again soon.']\n",
            "Context:\n",
            " [''] \n",
            "\n",
            "Category: thanks\n",
            "Data:\n",
            " ['Thanks', 'Thank you', \"That's helpful\", 'Awesome, thanks', 'Thanks for helping me']\n",
            "Possible responses:\n",
            " ['Happy to help!', 'Any time!', 'My pleasure']\n",
            "Context:\n",
            " [''] \n",
            "\n",
            "Category: noanswer\n",
            "Data:\n",
            " []\n",
            "Possible responses:\n",
            " [\"Sorry, can't understand you\", 'Please give me more info', 'Not sure I understand']\n",
            "Context:\n",
            " [''] \n",
            "\n",
            "Category: options\n",
            "Data:\n",
            " ['How you could help me?', 'What you can do?', 'What help you provide?', 'How you can be helpful?', 'What support is offered']\n",
            "Possible responses:\n",
            " ['I can guide you through Adverse drug reaction list, Blood pressure tracking, Hospitals and Pharmacies', 'Offering support for Adverse drug reaction, Blood pressure, Hospitals and Pharmacies']\n",
            "Context:\n",
            " [''] \n",
            "\n",
            "Category: adverse_drug\n",
            "Data:\n",
            " ['How to check Adverse drug reaction?', 'Open adverse drugs module', 'Give me a list of drugs causing adverse behavior', 'List all drugs suitable for patient with adverse reaction', 'Which drugs dont have adverse reaction?']\n",
            "Possible responses:\n",
            " ['Navigating to Adverse drug reaction module']\n",
            "Context:\n",
            " [''] \n",
            "\n",
            "Category: blood_pressure\n",
            "Data:\n",
            " ['Open blood pressure module', 'Task related to blood pressure', 'Blood pressure data entry', 'I want to log blood pressure results', 'Blood pressure data management']\n",
            "Possible responses:\n",
            " ['Navigating to Blood Pressure module']\n",
            "Context:\n",
            " [''] \n",
            "\n",
            "Category: blood_pressure_search\n",
            "Data:\n",
            " ['I want to search for blood pressure result history', 'Blood pressure for patient', 'Load patient blood pressure result', 'Show blood pressure results for patient', 'Find blood pressure results by ID']\n",
            "Possible responses:\n",
            " ['Please provide Patient ID', 'Patient ID?']\n",
            "Context:\n",
            " ['search_blood_pressure_by_patient_id'] \n",
            "\n",
            "Category: search_blood_pressure_by_patient_id\n",
            "Data:\n",
            " []\n",
            "Possible responses:\n",
            " ['Loading Blood pressure result for Patient']\n",
            "Context:\n",
            " [''] \n",
            "\n",
            "Category: pharmacy_search\n",
            "Data:\n",
            " ['Find me a pharmacy', 'Find pharmacy', 'List of pharmacies nearby', 'Locate pharmacy', 'Search pharmacy']\n",
            "Possible responses:\n",
            " ['Please provide pharmacy name']\n",
            "Context:\n",
            " ['search_pharmacy_by_name'] \n",
            "\n",
            "Category: search_pharmacy_by_name\n",
            "Data:\n",
            " []\n",
            "Possible responses:\n",
            " ['Loading pharmacy details']\n",
            "Context:\n",
            " [''] \n",
            "\n",
            "Category: hospital_search\n",
            "Data:\n",
            " ['Lookup for hospital', 'Searching for hospital to transfer patient', 'I want to search hospital data', 'Hospital lookup for patient', 'Looking up hospital details']\n",
            "Possible responses:\n",
            " ['Please provide hospital name or location']\n",
            "Context:\n",
            " ['search_hospital_by_params'] \n",
            "\n",
            "Category: search_hospital_by_params\n",
            "Data:\n",
            " []\n",
            "Possible responses:\n",
            " ['Please provide hospital type']\n",
            "Context:\n",
            " ['search_hospital_by_type'] \n",
            "\n",
            "Category: search_hospital_by_type\n",
            "Data:\n",
            " []\n",
            "Possible responses:\n",
            " ['Loading hospital details']\n",
            "Context:\n",
            " [''] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dNXMNcM0pMc"
      },
      "source": [
        "Notice at some point some patterns are empty. There's also a fourth key called **context** that can link one context to another.\r\n",
        "\r\n",
        "```\r\n",
        "Category: pharmacy_search\r\n",
        "Data:\r\n",
        " ['Find me a pharmacy', 'Find pharmacy', 'List of pharmacies nearby', 'Locate pharmacy', 'Search pharmacy']\r\n",
        "Possible responses:\r\n",
        " ['Please provide pharmacy name']\r\n",
        "Context:\r\n",
        " ['search_pharmacy_by_name'] \r\n",
        "\r\n",
        "Category: search_pharmacy_by_name\r\n",
        "Data:\r\n",
        " []\r\n",
        "Possible responses:\r\n",
        " ['Loading pharmacy details']\r\n",
        "Context:\r\n",
        " [''] \r\n",
        " ```\r\n",
        "\r\n",
        " The category `search_pharmacy_by_name` doesn't have any data to provide, hwoever, it is linked as a subtopic for `pharmacy_search`, that can be invoked when the bot is requesting a pharmacy name to the user."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZS98OWkrxPIN"
      },
      "source": [
        "## Preprocessing\r\n",
        "\r\n",
        "At first we need to tokenize the possible messages the user can submit. Tokenization is a process in which each sentences is decomposed into a list of words.\r\n",
        "\r\n",
        "Each sentence must be stored inside a corpus of documents, each tag being attached. Also, the classes, represented by the tags, must be stored somewhere too.\r\n",
        "\r\n",
        "It's organized so we can create a **bag of word** matrix much later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34KoiQRjvYkX",
        "outputId": "cc13ec0c-fa02-4b5d-db30-46419562468f"
      },
      "source": [
        "# List of all the words present in the patterns\r\n",
        "words = []\r\n",
        "# List of all tags in the dataset\r\n",
        "classes = set()\r\n",
        "# Corpus representing a token + a tag\r\n",
        "documents = []\r\n",
        "\r\n",
        "for intent in intents['intents']:\r\n",
        "  for pattern in intent['patterns']:\r\n",
        "    word = nltk.word_tokenize(pattern)\r\n",
        "    words.extend(word)\r\n",
        "    documents.append((word, intent['tag']))\r\n",
        "    classes.add(intent['tag'])\r\n",
        "\r\n",
        "for word, tag in documents:\r\n",
        "  print(\"Topic:\", tag)\r\n",
        "  print(\"Tokens:\\n\", word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: greeting\n",
            "Tokens:\n",
            " ['Hi', 'there']\n",
            "Topic: greeting\n",
            "Tokens:\n",
            " ['How', 'are', 'you']\n",
            "Topic: greeting\n",
            "Tokens:\n",
            " ['Is', 'anyone', 'there', '?']\n",
            "Topic: greeting\n",
            "Tokens:\n",
            " ['Hey']\n",
            "Topic: greeting\n",
            "Tokens:\n",
            " ['Hola']\n",
            "Topic: greeting\n",
            "Tokens:\n",
            " ['Hello']\n",
            "Topic: greeting\n",
            "Tokens:\n",
            " ['Good', 'day']\n",
            "Topic: goodbye\n",
            "Tokens:\n",
            " ['Bye']\n",
            "Topic: goodbye\n",
            "Tokens:\n",
            " ['See', 'you', 'later']\n",
            "Topic: goodbye\n",
            "Tokens:\n",
            " ['Goodbye']\n",
            "Topic: goodbye\n",
            "Tokens:\n",
            " ['Nice', 'chatting', 'to', 'you', ',', 'bye']\n",
            "Topic: goodbye\n",
            "Tokens:\n",
            " ['Till', 'next', 'time']\n",
            "Topic: thanks\n",
            "Tokens:\n",
            " ['Thanks']\n",
            "Topic: thanks\n",
            "Tokens:\n",
            " ['Thank', 'you']\n",
            "Topic: thanks\n",
            "Tokens:\n",
            " ['That', \"'s\", 'helpful']\n",
            "Topic: thanks\n",
            "Tokens:\n",
            " ['Awesome', ',', 'thanks']\n",
            "Topic: thanks\n",
            "Tokens:\n",
            " ['Thanks', 'for', 'helping', 'me']\n",
            "Topic: options\n",
            "Tokens:\n",
            " ['How', 'you', 'could', 'help', 'me', '?']\n",
            "Topic: options\n",
            "Tokens:\n",
            " ['What', 'you', 'can', 'do', '?']\n",
            "Topic: options\n",
            "Tokens:\n",
            " ['What', 'help', 'you', 'provide', '?']\n",
            "Topic: options\n",
            "Tokens:\n",
            " ['How', 'you', 'can', 'be', 'helpful', '?']\n",
            "Topic: options\n",
            "Tokens:\n",
            " ['What', 'support', 'is', 'offered']\n",
            "Topic: adverse_drug\n",
            "Tokens:\n",
            " ['How', 'to', 'check', 'Adverse', 'drug', 'reaction', '?']\n",
            "Topic: adverse_drug\n",
            "Tokens:\n",
            " ['Open', 'adverse', 'drugs', 'module']\n",
            "Topic: adverse_drug\n",
            "Tokens:\n",
            " ['Give', 'me', 'a', 'list', 'of', 'drugs', 'causing', 'adverse', 'behavior']\n",
            "Topic: adverse_drug\n",
            "Tokens:\n",
            " ['List', 'all', 'drugs', 'suitable', 'for', 'patient', 'with', 'adverse', 'reaction']\n",
            "Topic: adverse_drug\n",
            "Tokens:\n",
            " ['Which', 'drugs', 'dont', 'have', 'adverse', 'reaction', '?']\n",
            "Topic: blood_pressure\n",
            "Tokens:\n",
            " ['Open', 'blood', 'pressure', 'module']\n",
            "Topic: blood_pressure\n",
            "Tokens:\n",
            " ['Task', 'related', 'to', 'blood', 'pressure']\n",
            "Topic: blood_pressure\n",
            "Tokens:\n",
            " ['Blood', 'pressure', 'data', 'entry']\n",
            "Topic: blood_pressure\n",
            "Tokens:\n",
            " ['I', 'want', 'to', 'log', 'blood', 'pressure', 'results']\n",
            "Topic: blood_pressure\n",
            "Tokens:\n",
            " ['Blood', 'pressure', 'data', 'management']\n",
            "Topic: blood_pressure_search\n",
            "Tokens:\n",
            " ['I', 'want', 'to', 'search', 'for', 'blood', 'pressure', 'result', 'history']\n",
            "Topic: blood_pressure_search\n",
            "Tokens:\n",
            " ['Blood', 'pressure', 'for', 'patient']\n",
            "Topic: blood_pressure_search\n",
            "Tokens:\n",
            " ['Load', 'patient', 'blood', 'pressure', 'result']\n",
            "Topic: blood_pressure_search\n",
            "Tokens:\n",
            " ['Show', 'blood', 'pressure', 'results', 'for', 'patient']\n",
            "Topic: blood_pressure_search\n",
            "Tokens:\n",
            " ['Find', 'blood', 'pressure', 'results', 'by', 'ID']\n",
            "Topic: pharmacy_search\n",
            "Tokens:\n",
            " ['Find', 'me', 'a', 'pharmacy']\n",
            "Topic: pharmacy_search\n",
            "Tokens:\n",
            " ['Find', 'pharmacy']\n",
            "Topic: pharmacy_search\n",
            "Tokens:\n",
            " ['List', 'of', 'pharmacies', 'nearby']\n",
            "Topic: pharmacy_search\n",
            "Tokens:\n",
            " ['Locate', 'pharmacy']\n",
            "Topic: pharmacy_search\n",
            "Tokens:\n",
            " ['Search', 'pharmacy']\n",
            "Topic: hospital_search\n",
            "Tokens:\n",
            " ['Lookup', 'for', 'hospital']\n",
            "Topic: hospital_search\n",
            "Tokens:\n",
            " ['Searching', 'for', 'hospital', 'to', 'transfer', 'patient']\n",
            "Topic: hospital_search\n",
            "Tokens:\n",
            " ['I', 'want', 'to', 'search', 'hospital', 'data']\n",
            "Topic: hospital_search\n",
            "Tokens:\n",
            " ['Hospital', 'lookup', 'for', 'patient']\n",
            "Topic: hospital_search\n",
            "Tokens:\n",
            " ['Looking', 'up', 'hospital', 'details']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDyVYtlL7hB5"
      },
      "source": [
        "The next step is **lemmatization**. Each word is converted into its lemma form to reduce the number of total words. As such, the number of words is reduced.\r\n",
        "\r\n",
        "In example, let's consider the following words: *\"sing\", \"singing\", \"sing\", \"sang\", \"sung\"*. Lemmatizing these words means they can all be connected to one single word: *\"sing\"*. The verbal declinations are removed and so are the singular and plural forms. In other languages, it can extend to other tenses or gendered forms.\r\n",
        "\r\n",
        "For that, we'll use NLTK's [wordnet](http://wordnet.princeton.edu/) lemmatizer, a lexical database of English. While we retrieve the lemma, we'll make sure they're in lower case and don't contain any punctuation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nc3wqbbG2R8p",
        "outputId": "00756b72-6c47-4812-be45-336985aad62c"
      },
      "source": [
        "# Init lemmatizer\r\n",
        "lemmatizer = WordNetLemmatizer()\r\n",
        "\r\n",
        "# Punctuation\r\n",
        "ignore_letters = ['!', '?', ',', '.']\r\n",
        "\r\n",
        "# Lemmatize, remove duplicates and sort\r\n",
        "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_letters]\r\n",
        "words = sorted(list(set(words)))\r\n",
        "\r\n",
        "# Sort classes\r\n",
        "classes = sorted(list(classes))\r\n",
        "\r\n",
        "print(f\"N° of documents: {len(documents)}\")\r\n",
        "print(f\"N° of classes: {len(classes)}\\n{classes}\")\r\n",
        "print(f\"N° of words: {len(words)}\\nList of unique words:\\n{words}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N° of documents: 47\n",
            "N° of classes: 9\n",
            "['adverse_drug', 'blood_pressure', 'blood_pressure_search', 'goodbye', 'greeting', 'hospital_search', 'options', 'pharmacy_search', 'thanks']\n",
            "N° of words: 87\n",
            "List of unique words:\n",
            "[\"'s\", 'a', 'adverse', 'all', 'anyone', 'are', 'awesome', 'be', 'behavior', 'blood', 'by', 'bye', 'can', 'causing', 'chatting', 'check', 'could', 'data', 'day', 'detail', 'do', 'dont', 'drug', 'entry', 'find', 'for', 'give', 'good', 'goodbye', 'have', 'hello', 'help', 'helpful', 'helping', 'hey', 'hi', 'history', 'hola', 'hospital', 'how', 'i', 'id', 'is', 'later', 'list', 'load', 'locate', 'log', 'looking', 'lookup', 'management', 'me', 'module', 'nearby', 'next', 'nice', 'of', 'offered', 'open', 'patient', 'pharmacy', 'pressure', 'provide', 'reaction', 'related', 'result', 'search', 'searching', 'see', 'show', 'suitable', 'support', 'task', 'thank', 'thanks', 'that', 'there', 'till', 'time', 'to', 'transfer', 'up', 'want', 'what', 'which', 'with', 'you']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_kw1uaqAx43"
      },
      "source": [
        "We can save the results in a pickle file and even use OOP to save the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2c5OsV3AcP2",
        "outputId": "7c564600-7ded-4642-e5d7-9c18830ec71a"
      },
      "source": [
        "def load_intents(fp):\r\n",
        "  with open(fp, 'r') as f:\r\n",
        "    intents = json.load(f)\r\n",
        "  return intents\r\n",
        "\r\n",
        "class IntentLoader:\r\n",
        "  def __init__(self, fp):\r\n",
        "    self.intents = load_intents(fp)\r\n",
        "    self.classes = []\r\n",
        "    self.documents = []\r\n",
        "    self.words = []\r\n",
        "    self.ignore_letters = ['!', '?', ',', '.']\r\n",
        "    self.lemmatizer = WordNetLemmatizer()\r\n",
        "  def fit(self):\r\n",
        "    for intent in self.intents['intents']:\r\n",
        "      for pattern in intent['patterns']:\r\n",
        "        word = nltk.word_tokenize(pattern)\r\n",
        "        self.words.extend(word)\r\n",
        "        self.documents.append((word, intent['tag']))\r\n",
        "        self.classes.append(intent['tag'])\r\n",
        "\r\n",
        "    # Lemmatize, remove duplicates and sort\r\n",
        "    self.words = [self.lemmatizer.lemmatize(w.lower()) for w in self.words if w not in self.ignore_letters]\r\n",
        "    self.words = sorted(list(set(self.words)))\r\n",
        "    # Sort classes\r\n",
        "    self.classes = sorted(list(set(self.classes)))\r\n",
        "    print(f\"Fit {len(self.documents)} documents for {len(self.classes)} classes (total words: {len(self.words)})\")\r\n",
        "\r\n",
        "  def describe(self):\r\n",
        "    if not self.classes:\r\n",
        "      print(\"No class found. Perform IntentLoader.fit() first.\")\r\n",
        "      return\r\n",
        "    print(f\"N° of documents: {len(self.documents)}\")\r\n",
        "    print(f\"N° of classes: {len(self.classes)}\\n{self.classes}\")\r\n",
        "    print(f\"N° of words: {len(self.words)}\\nList of unique words:\\n{self.words}\")  \r\n",
        "\r\n",
        "  def __str__(self):\r\n",
        "    return f\"N° of categories: {len(self.intents['intents'])}\"\r\n",
        "\r\n",
        "il = IntentLoader(path_data)\r\n",
        "il.fit()\r\n",
        "il.describe()\r\n",
        "\r\n",
        "with open(path_data.parent / 'intentloader.pkl','wb') as file:\r\n",
        "  pickle.dump(il, file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fit 47 documents for 9 classes (total words: 87)\n",
            "N° of documents: 47\n",
            "N° of classes: 9\n",
            "['adverse_drug', 'blood_pressure', 'blood_pressure_search', 'goodbye', 'greeting', 'hospital_search', 'options', 'pharmacy_search', 'thanks']\n",
            "N° of words: 87\n",
            "List of unique words:\n",
            "[\"'s\", 'a', 'adverse', 'all', 'anyone', 'are', 'awesome', 'be', 'behavior', 'blood', 'by', 'bye', 'can', 'causing', 'chatting', 'check', 'could', 'data', 'day', 'detail', 'do', 'dont', 'drug', 'entry', 'find', 'for', 'give', 'good', 'goodbye', 'have', 'hello', 'help', 'helpful', 'helping', 'hey', 'hi', 'history', 'hola', 'hospital', 'how', 'i', 'id', 'is', 'later', 'list', 'load', 'locate', 'log', 'looking', 'lookup', 'management', 'me', 'module', 'nearby', 'next', 'nice', 'of', 'offered', 'open', 'patient', 'pharmacy', 'pressure', 'provide', 'reaction', 'related', 'result', 'search', 'searching', 'see', 'show', 'suitable', 'support', 'task', 'thank', 'thanks', 'that', 'there', 'till', 'time', 'to', 'transfer', 'up', 'want', 'what', 'which', 'with', 'you']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pag530MmlIG-"
      },
      "source": [
        "# If saved somewhere, load this cell\r\n",
        "with open(path_data.parent / 'intentloader.pkl','rb') as file:\r\n",
        "  il = pickle.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqIxzXkwv7R7"
      },
      "source": [
        "Now we'll prepare the training set. The training set will regroup the data and the target and has the same length than the number of documents.\r\n",
        "\r\n",
        "* The data consists of a bag scrolling through every single unique word and checking if they are in the document or not (1 if they are, 0 otherwise).\r\n",
        "* The target marks the index where the class (topic) is located."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k02smjeJlo6m",
        "outputId": "2c37e954-4846-46a8-cc0e-2f55a8855ac5"
      },
      "source": [
        "train_set = []\r\n",
        "output_empty = [0] * len(il.classes)\r\n",
        "\r\n",
        "for doc_words, tag in il.documents:\r\n",
        "  bag = []\r\n",
        "\r\n",
        "  # Preprocessing of the words to compare them to the list of words in the corpus\r\n",
        "  word_patterns = [il.lemmatizer.lemmatize(word.lower()) for word in doc_words]\r\n",
        "\r\n",
        "  # Go through all the words and signal if the document word is there or not\r\n",
        "  for word in il.words:\r\n",
        "    bag.append(1) if word in word_patterns else bag.append(0)\r\n",
        "\r\n",
        "  # Marks the tag from the output\r\n",
        "  output_row = output_empty[:]\r\n",
        "  output_row[il.classes.index(tag)] = 1\r\n",
        "\r\n",
        "  # First column is the bow data, second column is the class\r\n",
        "  train_set.append([bag, output_row])\r\n",
        "\r\n",
        "\r\n",
        "random.shuffle(train_set)\r\n",
        "train_set = np.array(train_set, dtype=object)\r\n",
        "\r\n",
        "train_x = list(train_set[:,0])\r\n",
        "train_y = list(train_set[:,1])\r\n",
        "print(\"Training data is created\")\r\n",
        "print(f\"N° samples X: {len(train_x)}, n° samples y {len(train_y)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data is created\n",
            "N° samples X: 47, n° samples y 47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdbR2Q8g3vt6"
      },
      "source": [
        "## Create model\r\n",
        "\r\n",
        "The model is a simple artificial neural network, composed of some regular dense layers, for classification. We'll use cross-entropy loss as a criterion and the SGD as the optimizer.\r\n",
        "\r\n",
        "We will run the training over 200 epochs and maintain a batch size of 5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-BAuYjE3u7K",
        "outputId": "8cf5bb9d-f4ac-4c32-9070-04a522f1d9d4"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "print(f\"Current device: {device}\")\r\n",
        "\r\n",
        "layers = [nn.Linear(len(train_x[0]), 128),\r\n",
        "          nn.ReLU(),\r\n",
        "          nn.Dropout(0.5),\r\n",
        "          nn.Linear(128, 64),\r\n",
        "          nn.ReLU(),\r\n",
        "          nn.Dropout(0.5),\r\n",
        "          nn.Linear(64, len(train_y[0]))]\r\n",
        "\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "model = nn.Sequential(*layers)\r\n",
        "optim = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-6, momentum=0.9, nesterov=True)\r\n",
        "\r\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current device: cpu\n",
            "Sequential(\n",
            "  (0): Linear(in_features=87, out_features=128, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Dropout(p=0.5, inplace=False)\n",
            "  (3): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (4): ReLU()\n",
            "  (5): Dropout(p=0.5, inplace=False)\n",
            "  (6): Linear(in_features=64, out_features=9, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfwByiaJ6e5n",
        "outputId": "70573268-4cf7-454b-ff9c-fdb1aec8f955"
      },
      "source": [
        "# Prep the dataset\r\n",
        "epochs=200\r\n",
        "batch_size=5\r\n",
        "\r\n",
        "train_ds = TensorDataset(torch.Tensor(train_x), torch.Tensor(train_y))\r\n",
        "print(f\"N° of documents in dataset: {len(train_ds)}\")\r\n",
        "\r\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size)\r\n",
        "print(f\"N° of batches {len(train_dl)} (batch size {train_dl.batch_size})\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N° of documents in dataset: 47\n",
            "N° of batches 10 (batch size 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBWIxevR827F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714,
          "referenced_widgets": [
            "f0cc19dbaaca4c50979e1fb841dabc3d",
            "591f378101fc446f85fb36ded6b29968",
            "85579c3ad49a4c389f752e28650cd2b2",
            "f9fdda14f7744c8d8b946df57cefd798",
            "204da43c2f904e4dbd20d954e374bf2e",
            "0f2451d81ca84363916d00836088e227",
            "3997a82b4bbe4e72b498932a13371734",
            "150626e5babf4b139e0f408ca8455392"
          ]
        },
        "outputId": "1d23d50c-b44a-4e47-a612-37a07808f7f2"
      },
      "source": [
        "# Training model\r\n",
        "\r\n",
        "# Note for criterion\r\n",
        "# output = torch.autograd.Variable(torch.randn(10, 120).float())\r\n",
        "# target = torch.autograd.Variable(torch.FloatTensor(10).uniform_(0, 120).long())\r\n",
        "\r\n",
        "model = model.to(device)\r\n",
        "criterion = criterion.to(device)\r\n",
        "\r\n",
        "model.zero_grad()\r\n",
        "model.train()\r\n",
        "\r\n",
        "loss_history = []\r\n",
        "for epoch in trange(epochs):\r\n",
        "\r\n",
        "  loss_batch = 0\r\n",
        "  for bn, (data, label) in enumerate(train_dl):\r\n",
        "    data, label = data.to(device), label.to(device)\r\n",
        "\r\n",
        "    # Forward pass\r\n",
        "    output = model(data)\r\n",
        "    loss = criterion(output, label.argmax(dim=1))\r\n",
        "\r\n",
        "    optim.zero_grad()\r\n",
        "    loss.backward()\r\n",
        "    optim.step()  \r\n",
        "\r\n",
        "    # Register loss\r\n",
        "    loss_batch += loss.detach().item()\r\n",
        "\r\n",
        "  loss_history.append(loss_batch / len(train_dl))\r\n",
        "  if (epoch+1)%10==0:\r\n",
        "    print(f\"Current loss: {loss_batch:.2f}\")\r\n",
        "\r\n",
        "torch.save(model.state_dict(), path_data.parent / 'chatbot_model')\r\n",
        "\r\n",
        "plt.plot(np.array(loss_history))\r\n",
        "plt.title(\"Train loss\")\r\n",
        "plt.xlabel(\"Epochs\")\r\n",
        "plt.ylabel(\"Loss\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0cc19dbaaca4c50979e1fb841dabc3d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Current loss: 20.80\n",
            "Current loss: 13.75\n",
            "Current loss: 5.97\n",
            "Current loss: 3.03\n",
            "Current loss: 2.53\n",
            "Current loss: 2.64\n",
            "Current loss: 0.90\n",
            "Current loss: 0.35\n",
            "Current loss: 0.86\n",
            "Current loss: 0.62\n",
            "Current loss: 0.87\n",
            "Current loss: 0.55\n",
            "Current loss: 0.16\n",
            "Current loss: 0.20\n",
            "Current loss: 0.24\n",
            "Current loss: 0.30\n",
            "Current loss: 0.14\n",
            "Current loss: 0.12\n",
            "Current loss: 1.66\n",
            "Current loss: 0.06\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXycZb338c8v+9IszdI0S5N0pXRvKZRdBGSVRQEtIopHHlzA5Sg+gJ6j6OM5Kh49iICILKKyqIgsslMKhUIL3fcladomaZqlzd7scz1/zJ2QLmnTNpOZZL7v1yuvztxzZ+aXO9P55rqu+74uc84hIiLhKyLYBYiISHApCEREwpyCQEQkzCkIRETCnIJARCTMKQhERMKcgkCkH8zsZTP74jF+73YzO3+gaxIZKFHBLkAkUMysqdfdBKAN6PLuf8U593h/n8s5d/FA1iYSShQEMmw550Z03zaz7cCNzrk3DtzPzKKcc52DWZtIKFHXkIQdMzvHzMrM7DYz2w08amYjzexfZlZtZrXe7bxe3/OWmd3o3b7BzN41s//x9i0xs361GMws1szuNrNd3tfdZhbrPZbhvW6dme01s3fMLMJ77DYzKzezRjPbbGbnBeDQSJhSEEi4Gg2kAQXATfj/Lzzq3c8HWoB7D/P984DNQAZwF/CwmVk/XvcHwKnALGAmcArwH95j3wXKgEwgC/g+4MzsBOAW4GTnXBJwIbC9nz+nyBEpCCRc+YAfOefanHMtzrk9zrl/OOf2Oecagf8CPnaY79/hnPuDc64LeAzIxv/hfSTXAT9xzlU556qBHwPXe491eM9T4JzrcM694/yTgXUBscAUM4t2zm13zhUf008tcggKAglX1c651u47ZpZgZr83sx1m1gAsAlLNLLKP79/dfcM5t8+7OaKPfXvLAXb0ur/D2wbwS6AIeM3MtpnZ7d7zFwHfBu4EqszsKTPLQWSAKAgkXB047e53gROAec65ZOBsb3t/unuOxi783U/d8r1tOOcanXPfdc6NAy4HvtM9FuCce8I5d6b3vQ74xQDXJWFMQSDil4R/XKDOzNKAHwXodZ4E/sPMMs0sA/gh8BcAM/ukmU3wxhrq8XcJ+czsBDM71xtUbvXq9AWoPglDCgIRv7uBeKAGWAK8EqDX+SmwDFgDrAVWeNsAJgJvAE3A+8D9zrmF+McHfu7VthsYBdwRoPokDJkWphERCW9qEYiIhDkFgYhImFMQiIiEOQWBiEiYG3KTzmVkZLjCwsJglyEiMqQsX768xjmXeajHhlwQFBYWsmzZsmCXISIypJjZjr4eU9eQiEiYUxCIiIQ5BYGISJhTEIiIhDkFgYhImFMQiIiEOQWBiEiYG3LXERyr+pYO1pTVsbWyiVn5qczJHxnskkREQkLYBMFbm6v41lOrAIiONH577RwumjY6yFWJiARf2HQNnTkhgydunMei732c6bkp3PzECu5/q4gun9ZjEJHwNuQWppk7d6473ikmmto6ue0fa3hxTQWxUREkxkbxwOdP4pSxaQNUpYhIaDGz5c65uYd6LGxaBL2NiI3i3mtn89trZ3P9qQXER0fyg3+upaNLy8CKSPgJyyAAMDMum5nDf3xyCj++fCpbq5p4dHFJsMsSERl0YRsEvZ0/JYvzTxzFL1/dzHtFNcEuR0RkUCkIPL+6ZhZjMxL5yp+Xs3TbnmCXIyIyaBQEnpSEaP74pVNIHxHDtX9Ywt1vbKG9U2MGIjL8KQh6yUmN54VvnMnlM3O4+42tXHrPOxRXNwW7LBGRgFIQHCApLpq758/mkRvmsre5nRsfW0Z9S0ewyxIRCRgFQR/OnZzFA9efROnefdz699XBLkdEJGAUBIdxcmEaXz9nPK9vqKSqsTXY5YiIBISC4AgumOqfj2ixTisVkWFKQXAEU7KTSUuM4Z0tCgIRGZ4UBEcQEWGcOSGDRVtrGGrzMomI9EfAgsDMxpjZQjPbYGbrzexbh9jHzOweMysyszVmNidQ9RyPsyZmUNPUxqbdjcEuRURkwAWyRdAJfNc5NwU4FbjZzKYcsM/FwETv6ybgdwGs55idNTETgGdXlge5EhGRgRewIHDOVTjnVni3G4GNQO4Bu10B/Mn5LQFSzSw7UDUdq9EpcVw1J4+H3y1h0+6GYJcjIjKgBmWMwMwKgdnA0gMeygVKe90v4+CwwMxuMrNlZrasuro6UGUe1g8uPZHk+Gi+/8zaoLy+iEigBDwIzGwE8A/g2865Y/pz2jn3oHNurnNubmZm5sAW2E9piTF87WPjWbGzjor6lqDUICISCAENAjOLxh8CjzvnnjnELuXAmF7387xtIelkbwWzlTvrglyJiMjACeRZQwY8DGx0zv26j92eB77gnT10KlDvnKsIVE3Ha0p2MjFREawqVRCIyPARFcDnPgO4HlhrZqu8bd8H8gGccw8ALwGXAEXAPuBLAaznuMVERTAtJ5mVO2uDXYqIyIAJWBA4594F7Aj7OODmQNUQCLPGjOTxpTvo6PIRHanr8URk6NMn2VGanZ9KW6ePzbq4TESGCQXBUZqdnwrAQ+9so6hKi9aIyNCnIDhKuanxXD4zh+dW7+KS37xDU1tnsEsSETkuCoKjZGbcc+1s7pk/m/YuHyXVzcEuSUTkuCgIjtGkrCQASvYoCERkaFMQHKOC9ATMUItARIY8BcExiouOJCclnpIaDRiLyNCmIDgO4zITKalRi0BEhjYFwXEoTPcHgVYuE5GhTEFwHMZmJNLQ2sne5vZglyIicswUBMdhbGYigLqHRGRIUxAch3EZ/iDYpiAQkSFMQXAcclPjiYowzTskIkOaguA4REVG8PHJo3jyg51atUxEhiwFwXH6z0un0OVz/PTFjcEuRUTkmCgIjlN+egJfOXscL66poKx2X7DLERE5agqCAfCxE0YBsLFCYwUiMvQoCAbACaP9E9Bt3t0Q5EpERI6egmAAjIiNYkxaPBt19pCIDEEKggFyQlayTiMVkSFJQTBAJo9OoqSmmbbOrmCXIiJyVBQEA2RydhJdPqd1jEVkyFEQDJDJ3oDxJp05JCJDjIJggBSmJxITFcHmSgWBiAwtCoIBEhUZwbiMRLZVq2tIRIYWBcEAyhsZT1mt5hwSkaFFQTCA8kYmUF7bohXLRGRIURAMoNzUeBrbOmlo6Qx2KSIi/aYgGEB5I+MBKKvT5HMiMnQoCAZQ3sgEAI0TiMiQoiAYQD0tAgWBiAwhCoIBlJoQTWJMpNYlEJEhRUEwgMyM3JHxlKtFICJDiIJggOWNTFDXkIgMKQqCAea/qExdQyIydCgIBljeyHgaWjtpaO0IdikiIv0SsCAws0fMrMrM1vXx+DlmVm9mq7yvHwaqlsGUm+o/hVTjBCIyVASyRfBH4KIj7POOc26W9/WTANYyaLJT4wCoqFcQiMjQELAgcM4tAvYG6vlDVU6K/1qCivrWIFciItI/wR4jOM3MVpvZy2Y2ta+dzOwmM1tmZsuqq6sHs76jlpkUS2SEUVGnIBCRoSGYQbACKHDOzQR+Czzb147OuQedc3Odc3MzMzMHrcBjERlhZCXFqkUgIkNG0ILAOdfgnGvybr8ERJtZRrDqGUijU+I0RiAiQ0bQgsDMRpuZebdP8WrZE6x6BlJ2ajy71SIQkSEiKlBPbGZPAucAGWZWBvwIiAZwzj0AXA18zcw6gRZgvhsmK7pkJ8exYGMlzjm8rBMRCVkBCwLn3LVHePxe4N5AvX4wZafG09rho25fByMTY4JdjojIYQX7rKFhKTul+1oCdQ+JSOhTEATAR0GgAWMRCX0KggDI1kVlIjKEKAgCIDMplqgIU4tARIYEBUEAREYYWclxvFu0h4WbqhgmJ0OJyDClIAiQ808cxbryer70xw9ZsbMu2OWIiPRJQRAgP75iGq/9+9kAFFc3BbkaEZG+KQgCKD8tgcgIY8ee5mCXIiLSJwVBAEVHRpA3Mp4de7R0pYiELgVBgOWnJbBzr4JAREKXgiDACtIT2F6jriERCV0KggArSEukobWTun3twS5FROSQFAQBVpDuX8xe4wQiEqoUBAFWkJ4IwA6NE4hIiFIQBFh+mtci0DiBiIQoBUGAxcdEMiopVi0CEQlZCoJBUJieyE6NEYhIiFIQDIL89AR27FXXkIiEJgXBIChIS6CyoY2W9q5glyIichAFwSDI904h1RXGIhKKFASDoLD7FFJNPiciIUhBMAgK1CIQkRDWryAws0Qzi/BuTzKzy80sOrClDR+pCTEkx0WxXS0CEQlB/W0RLALizCwXeA24HvhjoIoajgrSEzXNhIiEpP4GgTnn9gGfBu53zl0DTA1cWcNPQbqmoxaR0NTvIDCz04DrgBe9bZGBKWl4KkhPoLy2hY4uX7BLERHZT3+D4NvAHcA/nXPrzWwcsDBwZQ0/BWmJdPocu+pagl2KiMh+ovqzk3PubeBtAG/QuMY5981AFjbcdJ85VFLT3DMjqYhIKOjvWUNPmFmymSUC64ANZva9wJY2vEwenQzAxorGIFciIrK//nYNTXHONQBXAi8DY/GfOST9lJIQTd7IeNbtqg92KSIi++lvEER71w1cCTzvnOsAXODKGp6m5aSwvlxBICKhpb9B8HtgO5AILDKzAqAhUEUNV9Nyk9m+Zx8NrR3BLkVEpEe/gsA5d49zLtc5d4nz2wF8PMC1DTtTc1MA2LBLGSoioaO/g8UpZvZrM1vmff0Kf+tAjsK0HH8QrFP3kIiEkP52DT0CNAKf8b4agEcDVdRwlZkUS1ZyLOvVIhCRENKv6wiA8c65q3rd/7GZrQpEQcPdtJwUtQhEJKT0t0XQYmZndt8xszOAw14ia2aPmFmVma3r43Ezs3vMrMjM1pjZnP6XPXRNzU2huLpJq5WJSMjobxB8FbjPzLab2XbgXuArR/iePwIXHebxi4GJ3tdNwO/6WcuQNi0nGZ+DjbvVPSQioaG/Zw2tds7NBGYAM5xzs4Fzj/A9i4C9h9nlCuBP3llIS4BUM8vuZ91D1jTvzCFdTyAioeKoVihzzjV4VxgDfOc4XzsXKO11v8zbdhAzu6n7jKXq6urjfNngyk6JIy0xhnXlahGISGg4nqUqbcCqOALn3IPOubnOubmZmZmD9bIBYWZMzUnWVBMiEjKOJwiOd4qJcmBMr/t53rZhb2pOClsqG2nr1ICxiATfYYPAzBrNrOEQX41AznG+9vPAF7yzh04F6p1zFcf5nEPCtNxkOrocWyubgl2KiMjhryNwziUd6xOb2ZPAOUCGmZUBPwKived9AHgJuAQoAvYBXzrW1xpqZo1JxQxeWLOrZ/BYRCRY+ntB2VFzzl17hMcdcHOgXj+U5Y1M4IqZOfxx8Xb+7YyxZCXHBbskEQljxzNGIMfh3z8xiS6f4zcLtga7FBEJcwqCIClIT+SauXk8vbyM+hZNSy0iwaMgCKLPnpxPe6ePl9eGxRi5iIQoBUEQzcxLYVxmIs+sDIuzZkUkRCkIgsjMuGpOHh+U7KV0775glyMiYUpBEGSXz/RfjvHahsogVyIi4UpBEGRj0hLISo5lbVldsEsRkTClIAgB03NTWKvZSEUkSBQEIWBabgrbapppausMdikiEoYUBCFgem4KzsHGCk1NLSKDT0EQAqZ78w2tLVP3kIgMPgVBCBiVHMeopFgtai8iQaEgCBHTc1NY7Z055PM56va1B7kiEQkXCoIQcdbEDIqrm1m6bQ93vrCej//PW/h8x7v2j4jIkSkIQsT8U/LJTIrljn+u5c9LdlC7r4M6TUYnIoNAQRAi4qIjufmc8WyrbsZ5DYGaprbgFiUiYUFBEELmn5LPJ2dkc/PHxwNQ3aggEJHAUxCEkLjoSO793Bw+NTsPUItARAaHgiAEZY6IBdQiEJHBoSAIQcnxUcRERlDTpFNIRSTwFAQhyMzIGBGjFoGIDAoFQYjKSIrVGIGIDAoFQYjKGKEgEJHBoSAIUZkjYtU1JCKDQkEQojKSYtjT3K5pJkQk4BQEISpjRCxdPsc/V5bz6fsX09rRFeySRGSYUhCEqAzvWoJfv76FFTvrWLlTaxqLSGAoCEJUZpI/CMrrWgB4v7gmmOWIyDCmIAhR3S0CgJEJ0bxXvCeI1YjIcKYgCFHd00yMSYvnsyfns6q0jmYtbi8iAaAgCFHJ8VFkjIjl07PzOGNCOp0+x4fb9wa7LBEZhqKCXYAcmpnx5q0fIzEmivZOH9GRxpJteznnhFHBLk1Ehhm1CEJYclw0kRFGfEwk4zJGUFTVCPgHkLWmsYgMFAXBEFGYkUBJTTMAn39oKb94ZVOQKxKR4UJBMEQUpidSureF+n0dlNQ0s6uuNdglicgwoSAYIgozEmnv8vH21moALWwvIgMmoEFgZheZ2WYzKzKz2w/x+A1mVm1mq7yvGwNZz1BWmJ4IwKvrdwNQrzECERkgATtryMwigfuATwBlwIdm9rxzbsMBu/7VOXdLoOoYLgozEgB4a1MVoBaBiAycQLYITgGKnHPbnHPtwFPAFQF8vWEtKymOuOgImtv9k8/Vt3RoZlIRGRCBDIJcoLTX/TJv24GuMrM1Zva0mY051BOZ2U1mtszMllVXVwei1pAXEWE93UNm4Bw0tupKYxE5fsEeLH4BKHTOzQBeBx471E7OuQedc3Odc3MzMzMHtcBQUpDu7x46ISsJgFqNE4jIAAhkEJQDvf/Cz/O29XDO7XHOdS/D9RBwUgDrGfIKM/wtgnlj0wCNE4jIwAhkEHwITDSzsWYWA8wHnu+9g5ll97p7ObAxgPUMedNzU4iJiuC08RkAurpYRAZEwM4acs51mtktwKtAJPCIc269mf0EWOacex74ppldDnQCe4EbAlXPcHDp9GxOG5fe0xKoV4tARAZAQCedc869BLx0wLYf9rp9B3BHIGsYTsyM9F7rFNTtUxCIyPEL9mCxHIOU+GhAQSAiA0NBMARFRUaQFBtF7b52/vz+dp78YGewSxKRIUzrEQxRqYnR1Ld08JsFRdQ0tZEQE8kVsw51mYaIyOGpRTBEpcbHsKWysScEvvf3NWyrbgp2WSIyBCkIhqjUhGg2VDQAcNfVM+hyjn+sKAtyVSIyFCkIhqiU+GicN9XQxyZlcsaEDJ5btQvn+jf/UFNbp+YqEhFAQTBkpSb4zxwqSE8gKS6aK2bmUFbbwoOLtvH5h5ZSundfn9/b2NrB6T9bwN+Xl/a5j4iEDwXBEJUaHwPA1JxkAC6YmkVsVAQ/e3kT7xbV8PTyMto7fdyzYCt7m/e/AvmDkr00tHaypVJjCiKis4aGrO4WwdScFACS4qL5P2eNo7R2HyU1zbyxsZLCjAR+/foWUhOi+ezJY7j58ZXccu4E3iveA0BVY1ufzy8i4UNBMESlJvhbBFO8FgHArReeAMDv3y7mZy9v4t43iwDYUtnI+l0NvLGxkvYuH1UN/vWOu/8VkfCmrqEh6rTx6Vw6I5tTCtMOeuz8KVkAFFc3A7BldxMbvTOMFm2pZtPuRgCqvRbBip211DZrAjuRcKUgGKJyU+O573NzSIw9uFE3PnME4zISiYmM4KKpo9lS1ciGXQ0kxEQSE+n/lc8ak0p1YxvtnT7mP7iE+xb6Ww+le/fR2KqpK0TCibqGhqnbL57MnuZ22jq6eGX9bhZtrWZabgoFaQks2FTFeZNHsaq0jqKqJto7fazbVY/P57jyvsWcNTGDu+fPDvaPICKDREEwTF0wdTQA7xXVAFC6t4XzJmdx+8WT+e6+Dt71tn+4fS8AGysa2VbTxJ7mdl5at5sf7+sgxRuQFpHhTV1Dw9xEb1lLgCnZycRFRzI6JY5RSf7prD/wgqC+pYNX1u0GoL3Tx7Oryg9+sn5aU1ZHW2fXcVQtIoNJQTDMZYyIIS3x4DOMRiX7g2CZFwQAf11WSmJMJFOyk/nje9v5j2fXsnBz1VG9XnVjG1fet5hnVhx7kIjI4FIQDHNmxsRRI4iKMCaMGtGzPdNb4KayoY0xafGAv/toel4K159WQElNM39ZspOfvLCh39NWAFTUt+BzsGNP31c2i0ho0RhBGLhsZg4F6QnERUf2bBuZEENUhNHpc0zN9l+UVrq3hVljRjL/5DGcPSmTxUU1/N+n17BsRy0nH+I01UOpavCfkrq7vmXgfxARCQi1CMLA508t4K6rZ+63LSLCyPTGCQoyEjhxtL/baNaYFMyM3NR4Lp2eTWJMJH9f1v85iaqb/EFQUa+L1USGCgVBGOseMC5IS+yZqmLmmNSexxNjo7h0Rjb/WlNBc1snAD6f4y9LdvBMH1Ne97QIdNWyyJChrqEwlpkUB9RTmJ7AJdNHMzUnmeyU+P32uWxmDn9bVsbyHbWcMjaNr/1lOQs3V2PmD4rVpXUkxUXztXPGA1Dd5A+AivpWnHOY2WD/WCJylBQEYeyjrqFEUhNieqam6G1Gnr+FsKasjj3NbSzcXM3tF0/muVW7+MqflwP+M5N6gsCbtqK908fe5nbSvUFpEQld6hoKY9NzU8hJiWN0clyf+6TERzMuM5FVpfUsKd5LSnw0N501jgevP4nzTxzFBVOyqGlqp77FPy1F7xlNNU4gMjQoCMLY5+bls/j2c4mMOHz3zay8VFaX1fH+tj2cMjaNiAhjTFoCD33xZK6ZOwagZ73k6sY2xmUmArBbQSDSo7PLx9PLy+gKwZUBFQRhrj99+DO9Cep27t3HqePS93us+0N/W3UzzjmqGtuYkesfeK7QgLFIj3e21nDr31ezZNue/ba3dnTxradWsmNPc5AqUxBIP8zIS+m5PW/s/tcT5KclEBlhlNQ009DaSXunjxOzk4mKMCrq9r+WYEtlI/vaOwelZpFQU1a7b79/u60ureO5Vbt4bX1lMMoCFATSDydmJxMdaSTHRXFidvJ+j0VHRpCflsC2miaqG/0tgNEpcWQlx/V0DdU2t3PzEyu44H8Xcc+CokGvXyQUlNe17vdvt+51Q4qqgrd0rIJAjiguOpJ5Y9M578SsQ44njMtIZFt1c89AceaIWLJT4noGi+96dROvrd9NxohY3j+gWdyto8vHoi3VOOdo7/Tx0toKfL36Uourm1hTVheAn05kcFR4V9uX1+7fUu4OgK1VjYNeUzcFgfTLo186mV9ePeOQj43LTKSkprnnYrJRybGMToljd0MrLe1dvLC6gstn5nLN3DzWl9fT2nHwzKTPriznC498wLOryvn928V8/fEVvLHxo6byt59axY2PLcM5xz0LtnLDox8c9c/gnDuqeZOOh3PuoC4ACW+7vK7SXQd0mRZ7J1oUVTUN2vvzQAoC6ZfoyAiiIg/9dhmXOYK2Th+rSv1/sWeOiGPy6CRKapq58/n1NLV1cvVJecwtGEmnz7G69OC/7N8v9rcUfv7yJh54uxiAt7dUA1BU1cja8nqqGttYV97A40t38Nbmaur39b2SWkNrB4u9NRe6Xf3A+/zwufVH/8N7nHM89M42ttcceVDv78vLOOuuhWza3XDMryfDy66erqGDWwQRBg2tnT3X4Qw2BYEct3EZ/jOHXlm3m5ioCJLjo/jymeMYn5nIX5eVkjcynnlj05iTPxKAZTtq9/t+5xxLtu1hXGYilQ1ttHX6mJabzNteV9GzK3cRYWAG//vGFiq9lseqw3QV3ftmEdc9tJRX1/vXWKhpamP5jlr++mEpNU0H/2dzzvHh9r37dUcdaP2uBn764kYeWVzSs21VaR3f+duq/dZf6PI5fvdWMc7Bgo1Hnsa7or6FdeX1R9xvKHronW1cdPeioP2lGyq6fI7dDa2YeTP0eu+zlvYuyutaOMU7CWNrkMYJFARy3KbnpXDmhAyqm9oYl5GImREfE8lv5s8mJjKC+SePISLCGJkYw/jMRJYfEARltS3sqm/lhtML+dZ5E/nhZVOYf3I+ZbUtFFc38+yqcs6cmMmMvFTe3FRFVIQRYbByZ+0h6+nyOZ7zFta545m1VDe29ay70N7l49HFJdzxzFruemVTz3/Ipz4s5ZoH3ufp5YeeQwnoWbin9+l/9y0s4pkV5Tz87kfh8Or63ZTUNBMXHcHbm6uPePx++Nx6rn1wySG7zA703Kpy1u8aOqGxYGMVm3Y39nR/hKuqxla6fI4TspLo6HI9f4x0H5eLvBUFgzVgrCkm5LglxETxlxvnHdRVMy03hXdv+3jPwjgAcwvSeHZVOWfftZAun6MwI4F5Y/3XJswbm84Jo/0rqpXu9fev3/z4CspqW7j1ghPYvqeZ1aV1nDY+nerGNlburOPXr2/hpbUVvPKts3q6rpZu20NlQxvfPG8iD7xdzF2vbCIpLprYqAjm5I/kvoXFPfVUNbbx1Y+N4+cvbwLgz0t28JmTx1Db3E58TOR+U3e/vK4CgC2VTexpasMBCzdVERMVwb1vFnHVnDyykuP4/aJtjM1I5KJpo3lw0TbqWzpIid9/2c/fvVVMae0+7rxsKu8V1dDc3sXCTVVcPD27z+Nc3djGd/62mjMmZPCnfzvlqH5HweDzOdZ6LZ33t+1lwqikI3zH8NU9LnDK2DQ27W6krK6FUclxPUFw2vgMkuOigjZgrBaBDJiUhOiD1jkelRy339jC5bNyGJuRyPTcFOaNS2N1aT2/fn0LIxOimdhr4ZwxaQmMy0xkc2UjN545lstm5nD+if65kC6Zns3s/FSW76jlwUXFFFU1sWjrR395P7uqnBGxUXztY+OZf/IYnlu1izc2VjI7P5Vvnz+R7JQ4Hvj8HL513kSeXl7G+b9exL72Tr54WgFry+v5yQsbmPPT15n2o1c59b8XMPenr3Pb02sorm7mylk5AHxQspdnV5bT6XPc/7k5dHY57n5jC1sqG1ldWsfnTy3g3Mmj6PK5nnWju/l8joff3cYTS3fy3Kpymtv9LYHnV+/q2ae1o4vfLtjK//nTMkq8MYmX1lbQ5XO8X1xDQ6s/dOv2tfPA28W0d/qO+PtpbuukahAv8ttW00STN2vt0j7OFgsX3eMDJxWM9O77g6HYGx8ozEhgwqgRbK1Ui0DCwBkTMnjl22f33P+gZC9feGQpZ07MJOKAU1P/55qZNLV2cvakTMDfwnj+ljOYmpNCpBlPflBKZISREh/NXz8s5dzJWbxfvD+divgAABEjSURBVIcXVldwyfRs4mMiueH0Qv70/g527t3HlbNzmTcunffvOA+Ai6Zl84kpWby2oZLxmYmcO3kUf19exiOLSzhjQjoz8/xXVNe1dPBXb02GWy88gVfXV7JgUxWrSuuYmZfC+VOyuGZuHn9fVkZ7pyMywrhiVg6p8dEkxUXxjxXlXDh1dM/Pt7K0jpqmdgB++uJGoiKMy2fl8K81FZTu3cf7xXu4582tlNW2EBcdwSW/qeFXn5nJ86t3kRQbRWNbJ29vruaymTncs6CIRxaXkBofzfxT8g977L/2+Ao2VTTwzm0fJzYq8rD79lZU1UhKfEzPJIX9tbrU3xqYmpPMkm17B3022l11LWQmxRLdx0kO/dHa0bVfq/B4agF6FnjqPoV0+c5aCtMTiY2KZNaYkTz6Xgn3LSzi6+eMH9RjpSCQoDplbBpv3fpx4mMO/s/WPbjcW/dsqHMK/P9+enYuqQnRPLp4O798dRN/WFRCfnoCt144CfCf0XTe5FEs2FTFKYdYZW1abgrTcj+6cvob505kY0UDd109Y78PgDc3VVLZ0EbeyATmFo7k6eVlRBjcf91JANx41jie+GAn/1hRxnmTR5Hhzbr6lbPH8T+vbeHf/7aKn1w+jZSEaF7fUElUhDE9L4WVO+s4pTCN6+bl88yKcs66a6H3c6Zw11UzGJc5gpufWME3nlxJl8/x3U9M4rH3t/PahkpOH5/OEx/sAOChd0v4zNwx1Ld0MLJXV1y3t7dUs8g7C+vltbvJSo5jackevnHuxMPONbWuvJ6rH3iPUUlxvHDLmQe1+A5ndVkdiTGRXDevgO//cy3vFe8hLjqCUUlx5KbGExFh7K5vJS0xhuhI4+F3SyhMTzzkLLjddtW1sHxHLfHRkZw+IZ346Ei21TRTmJ6438+xrryeT9//HledlMfPPj29Z3tzWyeJsf372Fuxs5br/rCU//70ND41O69nu8/n+MvSHZwzaRT56Qn7fU9JTTNR3lxcB9adFBdFTmo8SXFR7KprYdn2vSwu2sPtF08G4HsXnkBNUxu/fHUzVQ2t3Hn51EELg4AGgZldBPwGiAQecs79/IDHY4E/AScBe4DPOue2B7ImCT2jU/qe/bQvE0Yl8Zv5s/jYpEyqG9v4wzsl3LewmAumZPHLq2fu94H1nQsmERsdwdzCg4PlQN3TaR/o3MkffTh9ckY2Wyob+dU1szhzYgaAf0xg6mheXrebT8/56EPjlnMnYmb88tXNvLp+N5+ZO4ZFW6qZNy6Nz56cz8qdKzl7UgZz8kfyX5+aRnunj0lZSZw+Pr3nQ+CxfzuFGx75gJWldVw5O5ey2hZeXOtfLKit08c3zp3Ab98s4qoH3mPlzjpuPHMst154Ait31vGLVzZR6XUH5aclEBVh3P9WERX1rTS2dlJe28IvrpqxX2usy+fYvqeZjRUN/NeLG0mOi6aivoUvPLIUMyM/LYE7L59KSU0zbR1d5I6M52cvbaK+pYOfXzWdnNR4unyO1WX1TMtN4fTx/jGg6x5a2vMaSXFRpCfGsH3PPiaPTuLcyaO4/61iYiIjePprpzEjL5W3t1Tzs5c28oNLT+SsiZmsLavnC48spdYbi0pPjCE7NY515Q184bQCfnLFNFrau6hqbOWbT66kvcvHP1aU8d0LJpExIpbfvLGVe97cyv+7Yhqfm/dR68k5R0tHFwkxH30cdnT5uOMfa2np6OKuVzZz8bRsunyO+OhI7n5jC/e8WcTMvDKe+foZREYYFfUt/NeLG/nXGv840vjMRB74/ElMzErCOceOvfvI8db6yE2NZ8XOOtbtaiBjRCxfOK0AwDvBYhZZybH84R3/yQeXz8plRl7KcbVq+sMCdVqXmUUCW4BPAGXAh8C1zrkNvfb5OjDDOfdVM5sPfMo599nDPe/cuXPdsmXLAlKzDF0LN1WRNzKeiVmDMyB5qG6O4uomHl1cwn9+cspBXS/rd9Xz2HvbeWaFf1zhzsum8Ll5Bdz/VhGfP7WgpwXRl9aOLspq9zFhVBIrd9ZyyxMrKa9r4fKZOfzqMzM555dvUd3Uxunj03mr15lKo5PjmJabzHvFe7j7s7Mor2vhxy9sICk2iitn5/LnJTuYOSaVM8an8+H2veyqa6WmyX8KL0ByXBRP3nQqq0vr+cGza5mem8KmikZ8ztHZ61TbuOgIoiMjaOv09ZyJ1eUcN501jtsvnszD75YQGWEUpieyu6GVteX1VNa3Mi03hUfeLaGxrZPzT8xiY0UDXT7HpTOy+fOSHXR2+YiKiOATU7J4a3MVqQkx/Gb+LFo6unj43RKqGtrIToljwaYqPjM3jxdWV9DS0YUZ/PTKafzgn+v41nkTOTE7ma/+ZTnpiTHsaW5nTFo8rR0+clLiqGlqp7yuhbMmZnDN3DFMHDWCRxeX8LdlZXz5zLE8/G4JJxeOZMXOOlLjo9nT3M6U7GQ2VDRwx8WTyRuZwH8+t46W9i6+fOZYMkbEcP9bxXT6HOdOHsWiLdVUNbZx0dTRPHD9Sfz3Sxt5cNE2AH502RS+dMbYg95b3//nWp78wN8dOTIhmoumjeaTM3KYNzatz+t5jsTMljvn5h7ysQAGwWnAnc65C737dwA4537Wa59XvX3eN7MoYDeQ6Q5TlIJAhrLtNc28uLaCL55eyIh+dlH0paG1g/joSKIjIyiva8GAnNR4Xl5bwYaKBsZlJnLh1NH7/aXb0NrB1/+yghtOL+S8E0fx1Iel/P7tYnbs3ceM3BTGZ44gfUQMk7KSODE7mQmjRvR0kXX3l68rr+fxpTuYW5BGSnw0GyoauHJWLpGRxu/fLmZEbBQ+5w+/2y6avF/X26Fs3t3Iv9bs4uvnTKC4uonvPb2GzbsbmJ6Xyj3zZ3HHM2vZUtnIGRMyuO2iyeSk7r+KXnunj6t+9x5ry+v5xJQsPnFiFpNGJzFrTCpf/uOHLNjkv5Zjak4yf/3KaTy4aBslNc0kREeyq97fZTNmZALPrirvuUYlwuD6Uwv48RXTuP7hpSwuquGqOXm0dvrwOcevrpnJlx79sGfKlElZI/jd509ifOaInt/zFx/9gNrmds6alMk5kzK5YOronrPHapra2FTRyOnj0w8aG+u2u76VFTtreWXdbt7YWMm+9q6els+xCFYQXA1c5Jy70bt/PTDPOXdLr33WefuUefeLvX1qDnium4CbAPLz80/asWNHQGoWCUc+n79rpL9954OhtaOL2KiIfveR721up6SmueesnG5bKht5dHEJU3NS+OSMbFITDh4/6dbZ5WP9rgY27W7gjAkZ5I309/M3tnZQt6/joH7/yoZW3vRaoicXph00qOycw+c44nof/dHa4T+9eExawhGDtS9DPgh6U4tAROToHS4IAjkCUQ6M6XU/z9t2yH28rqEU/IPGIiIySAIZBB8CE81srJnFAPOB5w/Y53ngi97tq4E3Dzc+ICIiAy9gnYLOuU4zuwV4Ff/po48459ab2U+AZc6554GHgT+bWRGwF39YiIjIIAro6JBz7iXgpQO2/bDX7VbgmkDWICIih6e5hkREwpyCQEQkzCkIRETCnIJARCTMBeyCskAxs2rgWC8tzgD6vFgtyEK1NtV1dEK1Lgjd2lTX0TnWugqcc5mHemDIBcHxMLNlfV1ZF2yhWpvqOjqhWheEbm2q6+gEoi51DYmIhDkFgYhImAu3IHgw2AUcRqjWprqOTqjWBaFbm+o6OgNeV1iNEYiIyMHCrUUgIiIHUBCIiIS5sAkCM7vIzDabWZGZ3R7EOsaY2UIz22Bm683sW972O82s3MxWeV+XBKG27Wa21nv9Zd62NDN73cy2ev8eeQX4ga/rhF7HZZWZNZjZt4NxzMzsETOr8hZV6t52yGNkfvd477k1ZjZnkOv6pZlt8l77n2aW6m0vNLOWXsftgUGuq8/fm5nd4R2vzWZ2YaDqOkxtf+1V13YzW+VtH8xj1tdnRODeZ865Yf+FfxrsYmAcEAOsBqYEqZZsYI53OwnYAkwB7gRuDfJx2g5kHLDtLuB27/btwC9C4He5GygIxjEDzgbmAOuOdIyAS4CXAQNOBZYOcl0XAFHe7V/0qquw935BOF6H/L15/w9WA7HAWO//bORg1nbA478CfhiEY9bXZ0TA3mfh0iI4BShyzm1zzrUDTwFXBKMQ51yFc26Fd7sR2AjkBqOWfroCeMy7/RhwZRBrATgPKHbOBWXhaufcIvxrZ/TW1zG6AviT81sCpJpZ9mDV5Zx7zTnX6d1dgn+VwEHVx/HqyxXAU865NudcCVCE///uoNdmZgZ8BngyUK/fl8N8RgTsfRYuQZALlPa6X0YIfPiaWSEwG1jqbbrFa9o9EowuGMABr5nZcjO7yduW5Zyr8G7vBrKCUFdv89n/P2ewjxn0fYxC6X33b/j/auw21sxWmtnbZnZWEOo51O8tlI7XWUClc25rr22DfswO+IwI2PssXIIg5JjZCOAfwLedcw3A74DxwCygAn+zdLCd6ZybA1wM3GxmZ/d+0PnboUE739j8S55eDvzd2xQKx2w/wT5Gh2JmPwA6gce9TRVAvnNuNvAd4AkzSx7EkkLu93YI17L/HxyDfswO8RnRY6DfZ+ESBOXAmF7387xtQWFm0fh/wY87554BcM5VOue6nHM+4A8EsEncF+dcufdvFfBPr4bK7mam92/VYNfVy8XACudcJYTGMfP0dYyC/r4zsxuATwLXeR8eeF0ve7zby/H3xU8arJoO83sL+vECMLMo4NPAX7u3DfYxO9RnBAF8n4VLEHwITDSzsd5flfOB54NRiNf3+DCw0Tn3617be/fpfQpYd+D3BriuRDNL6r6Nf6BxHf7j9EVvty8Czw1mXQfY76+0YB+zXvo6Rs8DX/DO6jgVqO/VtA84M7sI+L/A5c65fb22Z5pZpHd7HDAR2DaIdfX1e3semG9msWY21qvrg8Gqq5fzgU3OubLuDYN5zPr6jCCQ77PBGAUPhS/8I+tb8Cf5D4JYx5n4m3RrgFXe1yXAn4G13vbngexBrmsc/jM2VgPru48RkA4sALYCbwBpQTpuicAeIKXXtkE/ZviDqALowN8X++W+jhH+szju895za4G5g1xXEf6+4+732QPevld5v+NVwArgskGuq8/fG/AD73htBi4e7N+lt/2PwFcP2Hcwj1lfnxEBe59pigkRkTAXLl1DIiLSBwWBiEiYUxCIiIQ5BYGISJhTEIiIhDkFgYjHzLps/1lOB2yWWm/2ymBd5yByWFHBLkAkhLQ452YFuwiRwaYWgcgRePPS32X+tRo+MLMJ3vZCM3vTmzxtgZnle9uzzD///2rv63TvqSLN7A/eHPOvmVm8t/83vbnn15jZU0H6MSWMKQhEPhJ/QNfQZ3s9Vu+cmw7cC9ztbfst8Jhzbgb+Cd3u8bbfA7ztnJuJf7779d72icB9zrmpQB3+q1XBP7f8bO95vhqoH06kL7qyWMRjZk3OuRGH2L4dONc5t82bDGy3cy7dzGrwT4/Q4W2vcM5lmFk1kOeca+v1HIXA6865id7924Bo59xPzewVoAl4FnjWOdcU4B9VZD9qEYj0j+vj9tFo63W7i4/G6C7FP1fMHOBDb/ZLkUGjIBDpn8/2+vd97/Z7+GeyBbgOeMe7vQD4GoCZRZpZSl9PamYRwBjn3ELgNiAFOKhVIhJI+stD5CPx5i1W7nnFOdd9CulIM1uD/6/6a71t3wAeNbPvAdXAl7zt3wIeNLMv4//L/2v4Z7k8lEjgL15YGHCPc65uwH4ikX7QGIHIEXhjBHOdczXBrkUkENQ1JCIS5tQiEBEJc2oRiIiEOQWBiEiYUxCIiIQ5BYGISJhTEIiIhLn/D+6mz3UpCHfcAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81RXCM2Hfnw0"
      },
      "source": [
        "## Test model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVmvhMuUfqUl",
        "outputId": "109a4920-57aa-483a-e53b-e96e53c05bb2"
      },
      "source": [
        "# Load model\r\n",
        "cpu_device = torch.device('cpu')\r\n",
        "model = nn.Sequential(*layers)\r\n",
        "model.load_state_dict(torch.load(path_data.parent / 'chatbot_model', map_location=cpu_device))\r\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=87, out_features=128, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Dropout(p=0.5, inplace=False)\n",
              "  (3): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (4): ReLU()\n",
              "  (5): Dropout(p=0.5, inplace=False)\n",
              "  (6): Linear(in_features=64, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMbYwxMjga0B"
      },
      "source": [
        "class ChatBotApp:\r\n",
        "  def __init__(self, intents, model):\r\n",
        "    self.intents = intents\r\n",
        "    self.model = model\r\n",
        "\r\n",
        "  def clean_sentence(self, sentence):\r\n",
        "    s_words = nltk.word_tokenize(sentence)\r\n",
        "    s_words = [self.intents.lemmatizer.lemmatize(word.lower()) for word in s_words]\r\n",
        "    return s_words\r\n",
        "\r\n",
        "  def bow(self, sentence, verbose=False):\r\n",
        "    s_words = self.clean_sentence(sentence)\r\n",
        "    bag = [0]*len(self.intents.words)\r\n",
        "    for s in s_words:\r\n",
        "      for i, word in enumerate(self.intents.words):\r\n",
        "            if word == s: \r\n",
        "                # assign 1 if current word is in the vocabulary position\r\n",
        "                bag[i] = 1\r\n",
        "                if verbose:\r\n",
        "                    print (f\"found in bag: {word}\")\r\n",
        "    return torch.Tensor(bag) \r\n",
        "\r\n",
        "  @torch.no_grad()\r\n",
        "  def predict_class(self, sentence):\r\n",
        "    # filter below  threshold predictions\r\n",
        "    p = self.bow(sentence)\r\n",
        "    output = self.model(p)\r\n",
        "    sort_preds, sort_idx = output.sort(descending=True)\r\n",
        "    sort_classes = [self.intents.classes[i] for i in sort_idx.tolist()]\r\n",
        "    res_dict = {label:p for label, p in zip(sort_classes, sort_preds.tolist())}\r\n",
        "    return res_dict, self.intents.classes[output.argmax().item()]\r\n",
        "\r\n",
        "  def generate_response(self, sentence):\r\n",
        "    response = \"Sorry I didn't udnerstand your request.\"\r\n",
        "    _, best_tag =self.predict_class(sentence)\r\n",
        "    for intent in self.intents.intents['intents']:\r\n",
        "      if best_tag==intent['tag']:\r\n",
        "        response = random.choice(intent['responses'])\r\n",
        "        break\r\n",
        "    return response\r\n",
        "\r\n",
        "  def chat(self):\r\n",
        "    while True:\r\n",
        "      message = input(\"Please enter your message: \")\r\n",
        "      response = self.generate_response(message)\r\n",
        "      print(response)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        },
        "id": "u6phsP_MlWaX",
        "outputId": "acd1a715-af7c-434c-aa32-5f6c95a64ada"
      },
      "source": [
        "cb =  ChatBotApp(il, model)\r\n",
        "\r\n",
        "cb.chat()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please enter your message: Hello!\n",
            "Good to see you again\n",
            "Please enter your message: What's your name?\n",
            "Offering support for Adverse drug reaction, Blood pressure, Hospitals and Pharmacies\n",
            "Please enter your message: blood pressure?\n",
            "Navigating to Blood Pressure module\n",
            "Please enter your message: I'm fine fanks\n",
            "Hi there, how can I help?\n",
            "Please enter your message: By\n",
            "Good to see you again\n",
            "Please enter your message: bye\n",
            "See you!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \"\"\"\n\u001b[0;32m--> 566\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-858b2587ed31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mChatBotApp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mil\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-53-69ac2d5bdcb3>\u001b[0m in \u001b[0;36mchat\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please enter your message: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m       \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_8kWwFhk9GP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}